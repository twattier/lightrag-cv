# Epic 2.9: Custom Entity Creation During Ingestion - Brownfield Enhancement

## Status

**In Progress** üöß

---

## Progress Summary

- ‚úÖ **Story 2.9.1 Complete** - CIGREF Custom Entity Creation:
  - Domain and Profile entities created
  - Relationships established
  - QA Gate: PASS
  - Completed: 2025-01-14

- ‚úÖ **Story 2.9.2 Complete** - CV Custom Entity Creation:
  - Custom entities (CV, DOMAIN_JOB, JOB, XP) successfully created
  - Client-side relationship deduplication (44% API call reduction)
  - 742 lines of production code with comprehensive error handling
  - Exponential backoff retry logic implemented
  - 10 SQL validation queries provided
  - QA Gate: CONCERNS (80/100) - WAIVED for POC scope
  - Exit condition logic issue documented for future improvement
  - Completed: 2025-01-15

- ‚è∏Ô∏è **Story 2.9.3 Deferred** - Entity Creation Testing & Documentation (Optional):
  - Deferred to Phase 2 based on POC scope constraints
  - Manual SQL validation queries provided as interim solution

---

## Epic Status Tracking

- **Status**: 2/3 Stories Complete (67%)
- **Story 2.9.1**: ‚úÖ Done
- **Story 2.9.2**: ‚úÖ Done (with WAIVED concerns)
- **Story 2.9.3**: ‚è∏Ô∏è Deferred to Phase 2

---

## Epic Title

Knowledge Graph Enrichment with Custom Entities - Brownfield Enhancement

---

## Epic Goal

Enhance the existing CIGREF and CV ingestion pipelines to create custom typed entities and explicit relationships in the LightRAG knowledge graph, enabling more precise querying and better graph traversal for profile matching and candidate search.

---

## Epic Description

### Existing System Context

**Current relevant functionality:**
- CIGREF profiles ingested via `app/cigref_ingest/cigref_2_import.py`
- CVs ingested via `app/cv_ingest/cv4_import.py`
- Both workflows submit text with metadata headers to LightRAG `/documents/texts` endpoint
- LightRAG automatically extracts entities and relationships from text
- Current entity extraction is untyped and relies on LLM inference

**Technology stack:**
- Python 3.11 with asyncio
- LightRAG API (REST endpoints)
- PostgreSQL with pgvector and Apache AGE
- Existing ingestion scripts with retry logic and error handling

**Integration points:**
- LightRAG API `/graph/entity/exists` - Check if entity exists
- LightRAG API `/graph/entity/create` - Create custom entity with type
- LightRAG API `/graph/relation/create` - Create explicit relationship
- Existing PostgreSQL `document_metadata` table for tracking

### Enhancement Details

**What's being added/changed:**

1. **CIGREF Ingestion Enhancement** (`cigref_2_import.py`):
   - Create structured entities for each domain-profile pair:
     - `DOMAIN_PROFILE` entities (e.g., "APPLICATION LIFE CYCLE")
     - `PROFILE` entities (e.g., "Solution Architect", "DevOps Engineer")
   - Establish `DOMAIN_PROFILE ‚Üî PROFILE` relationships
   - Ensure entity uniqueness (create only if not present)

2. **CV Ingestion Enhancement** (`cv4_import.py`):
   - Create structured entities for each CV:
     - `CV` entities (e.g., "cv_001") with rich descriptions
     - `DOMAIN_JOB` entities (e.g., "Software Development")
     - `JOB` entities (e.g., "Senior Software Engineer")
     - `XP` entities (experience level: "Junior", "Mid", "Senior")
   - Establish relationships:
     - `CV ‚Üî DOMAIN_JOB`
     - `CV ‚Üî JOB`
     - `CV ‚Üî XP`
     - `DOMAIN_JOB ‚Üî JOB`
     - `JOB ‚Üî XP`
   - Ensure entity uniqueness across all CVs

**How it integrates:**
- Uses existing LightRAG API endpoints (no API changes required)
- Runs as part of existing ingestion workflows (backward compatible)
- Custom entities complement automatic entity extraction (additive approach)
- Entities stored in existing PostgreSQL graph storage (Apache AGE)

**Success criteria:**
1. All CIGREF domain-profiles have corresponding typed entities
2. All CVs have corresponding typed entities with metadata
3. Explicit relationships exist and are queryable via Cypher
4. No duplicate entities created (deduplication working)
5. Ingestion time impact < 20% increase
6. Entity queries return expected results

---

## Stories

### Story 2.9.1: CIGREF Custom Entity Creation

**Objective:** Enhance `cigref_2_import.py` to create custom `DOMAIN_PROFILE` and `PROFILE` entities with relationships.

**Implementation:**
- Add `create_cigref_entities()` async function
- For each domain in parsed CIGREF data:
  - Check if `DOMAIN_PROFILE` entity exists
  - Create if not present with entity_type="DOMAIN_PROFILE"
  - For each profile in domain:
    - Check if `PROFILE` entity exists
    - Create if not present with entity_type="PROFILE"
    - Create relationship `DOMAIN_PROFILE ‚Üî PROFILE`
- Add CLI flag `--skip-entities` to disable for testing
- Add structured logging for entity operations
- Update tests to verify entity creation

**Validation:**
```bash
# Run with entity creation
python -m app.cigref_ingest.cigref_2_import

# Verify entities in PostgreSQL
SELECT entity_name, entity_type
FROM lightrag_full_entities
WHERE entity_type IN ('DOMAIN_PROFILE', 'PROFILE')
LIMIT 20;
```

---

### Story 2.9.2: CV Custom Entity Creation

**Objective:** Enhance `cv4_import.py` to create custom `CV`, `DOMAIN_JOB`, `JOB`, and `XP` entities with comprehensive relationships.

**Implementation:**
- Add `create_cv_entities()` async function
- For each CV in manifest:
  - Extract metadata: `candidate_label`, `role_domain`, `job_title`, `experience_level`
  - Create entities:
    - `CV` entity: name=candidate_label, description="{role_domain} / {job_title} / {experience_level}"
    - `DOMAIN_JOB` entity: name=role_domain
    - `JOB` entity: name=job_title
    - `XP` entity: name=experience_level
  - Check existence for `DOMAIN_JOB`, `JOB`, `XP` (may be shared across CVs)
  - Create relationships:
    - `CV ‚Üî DOMAIN_JOB`
    - `CV ‚Üî JOB`
    - `CV ‚Üî XP`
    - `DOMAIN_JOB ‚Üî JOB`
    - `JOB ‚Üî XP`
- Add CLI flag `--skip-entities` to disable for testing
- Add retry logic for entity/relation API calls
- Track entity creation counts in summary

**Validation:**
```bash
# Run with entity creation
python -m app.cv_ingest.cv4_import

# Verify entities
SELECT entity_name, entity_type, COUNT(*)
FROM lightrag_full_entities
WHERE entity_type IN ('CV', 'DOMAIN_JOB', 'JOB', 'XP')
GROUP BY entity_name, entity_type;

# Verify relationships
SELECT src_id, relation, tgt_id
FROM lightrag_full_relations
WHERE src_id LIKE 'cv_%' OR tgt_id LIKE 'cv_%'
LIMIT 20;
```

---

### Story 2.9.3: Entity Creation Testing & Documentation (Optional)

**Objective:** Validate entity creation works correctly and document usage patterns.

**Implementation:**
- Create integration test script `test_entity_creation.py`
- Test scenarios:
  - Entity deduplication (same entity not created twice)
  - Relationship creation success
  - API error handling and retries
  - Performance impact measurement
- Update documentation:
  - Add entity schema to architecture docs
  - Document Cypher query patterns for custom entities
  - Add troubleshooting guide for entity API errors

**Validation:**
```bash
# Run integration tests
python -m pytest app/tests/test_entity_creation.py -v

# Query custom entities with Cypher
SELECT * FROM cypher('lightrag_graph', $$
  MATCH (cv:CV)-[r]-(entity)
  WHERE cv.name = 'cv_001'
  RETURN cv, r, entity
$$) AS (cv agtype, r agtype, entity agtype);
```

---

## Compatibility Requirements

- [x] Existing ingestion APIs remain unchanged
- [x] Database schema uses existing tables (`lightrag_full_entities`, `lightrag_full_relations`)
- [x] No changes to LightRAG API endpoints (uses existing endpoints)
- [x] Backward compatible: `--skip-entities` flag allows opt-out
- [x] Performance impact minimal: < 20% increase in ingestion time

---

## Risk Mitigation

**Primary Risk:** LightRAG entity API rate limiting or failures during batch entity creation

**Mitigation:**
- Implement retry logic with exponential backoff
- Add `--skip-entities` CLI flag for troubleshooting
- Create entities in small batches (10-20 at a time)
- Log all entity creation attempts for debugging

**Rollback Plan:**
- Use `--skip-entities` flag to revert to text-only ingestion
- Delete custom entities with PostgreSQL query:
  ```sql
  DELETE FROM lightrag_full_entities
  WHERE entity_type IN ('DOMAIN_PROFILE', 'PROFILE', 'CV', 'DOMAIN_JOB', 'JOB', 'XP');
  ```
- Re-run ingestion without entity creation

**Secondary Risk:** Entity name collisions (e.g., "Senior" as both experience level and job title word)

**Mitigation:**
- Use descriptive entity names with context (e.g., "XP:Senior" instead of "Senior")
- Check entity existence before creation
- Document entity naming conventions

---

## Definition of Done

- [x] Core stories completed with acceptance criteria met (2.9.1, 2.9.2)
- [x] CIGREF entities created for all domains and profiles
- [x] CV entities created for all valid CVs in manifest (46 CVs processed)
- [x] Explicit relationships established and queryable (5 relationship types)
- [x] No duplicate entities created (client-side deduplication implemented)
- [x] Ingestion scripts run without errors (exponential backoff retry logic)
- [x] Entity queries return expected results (10 SQL validation queries provided)
- [x] Performance impact documented (44% API call reduction via deduplication)
- [x] Code quality validated (QA reviews completed, gate files created)
- [x] No regression in existing ingestion functionality (backward compatible with --skip-entities flag)
- [ ] Automated test execution (Deferred to Phase 2 - Story 2.9.3)
- [ ] Comprehensive documentation (Deferred to Phase 2 - Story 2.9.3)

---

## Validation Checklist

### Scope Validation

- [x] Epic can be completed in 2-3 stories maximum
- [x] No architectural documentation required (uses existing LightRAG API)
- [x] Enhancement follows existing patterns (async functions, retry logic)
- [x] Integration complexity is manageable (3 new API endpoints)

### Risk Assessment

- [x] Risk to existing system is low (additive changes only)
- [x] Rollback plan is feasible (delete entities or use `--skip-entities`)
- [x] Testing approach covers existing functionality (backward compatibility)
- [x] Team has sufficient knowledge of LightRAG API and entity model

### Completeness Check

- [x] Epic goal is clear and achievable
- [x] Stories are properly scoped (CIGREF, CV, Testing)
- [x] Success criteria are measurable (entity counts, query results)
- [x] Dependencies identified (LightRAG API endpoints)

---

## Handoff to Story Manager

**Story Manager Handoff:**

"Please develop detailed user stories for this brownfield epic. Key considerations:

- This is an enhancement to the existing LightRAG-CV ingestion workflows running Python 3.11 + LightRAG + PostgreSQL
- Integration points: LightRAG API endpoints `/graph/entity/exists`, `/graph/entity/create`, `/graph/relation/create`
- Existing patterns to follow:
  - Async/await with httpx for API calls
  - Retry logic with exponential backoff (see existing ingestion code)
  - Structured logging with logger.info/error
  - CLI arguments for configuration
- Critical compatibility requirements:
  - Must not break existing text ingestion
  - Entity creation is additive (complements automatic extraction)
  - `--skip-entities` flag for troubleshooting
- Each story must include verification that existing ingestion functionality remains intact (backward compatibility testing)

The epic should maintain system integrity while delivering **enriched knowledge graph with typed entities and explicit relationships for precise querying**."

---

## Technical Implementation Notes

### LightRAG API Endpoints

Based on user requirements, the following endpoints will be used:

1. **Check Entity Existence**
   ```
   GET /graph/entity/exists?name={entity_name}
   Response: {"exists": true/false}
   ```

2. **Create Entity**
   ```
   POST /graph/entity/create
   Payload: {
     "name": "cv_001",
     "description": "Software Development / Senior Engineer / Senior",
     "entity_type": "CV"
   }
   Response: {"status": "success", "entity_id": "..."}
   ```

3. **Create Relationship**
   ```
   POST /graph/relation/create
   Payload: {
     "src_id": "cv_001",
     "tgt_id": "Software Development",
     "relation": "WORKS_IN"
   }
   Response: {"status": "success", "relation_id": "..."}
   ```

### Entity Schema

**CIGREF Entities:**
```python
# DOMAIN_PROFILE
{
  "name": "APPLICATION LIFE CYCLE",
  "description": "APPLICATION LIFE CYCLE",
  "entity_type": "DOMAIN_PROFILE"
}

# PROFILE
{
  "name": "Solution Architect",
  "description": "Solution Architect",
  "entity_type": "PROFILE"
}
```

**CV Entities:**
```python
# CV
{
  "name": "cv_001",
  "description": "Software Development / Senior Software Engineer / Senior",
  "entity_type": "CV"
}

# DOMAIN_JOB
{
  "name": "Software Development",
  "description": "Software Development",
  "entity_type": "DOMAIN_JOB"
}

# JOB
{
  "name": "Senior Software Engineer",
  "description": "Senior Software Engineer",
  "entity_type": "JOB"
}

# XP
{
  "name": "Senior",
  "description": "Senior",
  "entity_type": "XP"
}
```

### Relationship Types

- `DOMAIN_PROFILE ‚Üî PROFILE`: "HAS_PROFILE" / "BELONGS_TO_DOMAIN"
- `CV ‚Üî DOMAIN_JOB`: "WORKS_IN" / "CONTAINS_CV"
- `CV ‚Üî JOB`: "HAS_JOB_TITLE" / "DESCRIBES_CV"
- `CV ‚Üî XP`: "HAS_EXPERIENCE_LEVEL" / "LEVEL_OF_CV"
- `DOMAIN_JOB ‚Üî JOB`: "INCLUDES_JOB" / "PART_OF_DOMAIN"
- `JOB ‚Üî XP`: "REQUIRES_LEVEL" / "LEVEL_FOR_JOB"

### Code Pattern Example

**IMPORTANT:** All implementations must use `settings.lightrag_url` from `app.shared.config` and implement deduplication:

```python
from app.shared.config import settings

async def create_entity_if_not_exists(
    entity_name: str,
    entity_type: str,
    description: str,
    client: httpx.AsyncClient
) -> bool:
    """Create entity if it doesn't exist.

    Returns True if created, False if already exists.
    """
    # Check existence
    exists_response = await client.get(
        f"{settings.lightrag_url}/graph/entity/exists",
        params={"name": entity_name}
    )

    if exists_response.json().get("exists"):
        logger.debug(f"Entity already exists: {entity_name}")
        return False

    # Create entity
    create_response = await client.post(
        f"{settings.lightrag_url}/graph/entity/create",
        json={
            "name": entity_name,
            "description": description,
            "entity_type": entity_type
        }
    )
    create_response.raise_for_status()

    logger.info(f"Created entity: {entity_name} (type: {entity_type})")
    return True


async def create_relationship_if_not_exists(
    src_id: str,
    tgt_id: str,
    relation: str,
    client: httpx.AsyncClient
) -> bool:
    """Create relationship if it doesn't exist.

    CRITICAL: Prevents duplicate relationships in the graph.
    Returns True if created/exists, False if error.
    """
    # Check if relationship exists
    exists_response = await client.get(
        f"{settings.lightrag_url}/graph/relation/exists",
        params={"src_id": src_id, "tgt_id": tgt_id, "relation": relation}
    )

    if exists_response.json().get("exists"):
        logger.debug(f"Relationship already exists: {src_id} --[{relation}]--> {tgt_id}")
        return True  # Not created, but exists (success)

    # Create relationship
    response = await client.post(
        f"{settings.lightrag_url}/graph/relation/create",
        json={
            "src_id": src_id,
            "tgt_id": tgt_id,
            "relation": relation
        }
    )
    response.raise_for_status()

    logger.info(f"Created relationship: {src_id} --[{relation}]--> {tgt_id}")
    return True
```

**Configuration Requirements:**
- Import: `from app.shared.config import settings`
- Use: `settings.lightrag_url` (provides `http://{LIGHTRAG_HOST}:{LIGHTRAG_PORT}`)
- Retry limit: `settings.MAX_RETRIES` (default: 3)
- Timeout: `settings.INGESTION_TIMEOUT` (default: 1200 seconds)

---

## Performance Expectations

- **CIGREF**: ~10 domains √ó 20 profiles = 200 entities + 200 relationships
- **CV**: 50 CVs √ó 4 entities = 200 entities + (50√ó5) relationships = 450 operations
- **Total API calls**: ~850 (with deduplication reducing duplicates)
- **Expected time increase**: 10-20% (entity creation is fast, mostly API overhead)
- **Acceptable if**: Total ingestion time < 5 minutes for 50 CVs

---

## References

- PRD: [docs/prd.md](../prd.md) - Epic 2: Document Processing Pipeline
- Architecture: [docs/architecture/tech-stack.md](../architecture/tech-stack.md)
- Existing code:
  - [app/cigref_ingest/cigref_2_import.py](../../app/cigref_ingest/cigref_2_import.py)
  - [app/cv_ingest/cv4_import.py](../../app/cv_ingest/cv4_import.py)
- LightRAG API: http://localhost:9621/docs

---

**Document Version:** 1.0
**Created:** 2025-01-14
**Author:** Sarah (Product Owner)
**Status:** Ready for Implementation
